{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Cleaning Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Evaluate missing data\n",
        "*   Clean data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* /content/WalkthroughProject1/inputs/datasets/WeatherAustralia_raw.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate cleaned Train and Test sets, both saved under WalkthroughProject1/inputs/datasets/cleaned\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "  * Check: **Are all dates in the proper sequence (with no gaps) for each cities?**\n",
        "\n",
        "  * There are certain cities where some variables have 100% missing values\n",
        "\n",
        "* Missing Data\n",
        "  * DropVariables: ['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am']\n",
        "  * dropna() with less than 8%: ['WindDir9am', 'WindGustDir', 'WindGustSpeed', 'Humidity3pm', 'WindDir3pm', 'Temp3pm', 'RainTomorrow', 'RainToday', 'RainfallTomorrow', 'Rainfall', 'WindSpeed3pm', 'Humidity9am', 'Temp9am', 'WindSpeed9am', 'MinTemp', 'MaxTemp']\n",
        "  * imput with mediam: ['Pressure9am', 'Pressure3pm']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGT0ZCtwFAFv"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcidnQspZztu"
      },
      "source": [
        "! pip install matplotlib -U\n",
        "! pip install pandas-profiling==2.11.0\n",
        "! pip install missingno==0.4.2\n",
        "! pip install feature-engine==1.0.2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1anPl4iFEPR"
      },
      "source": [
        "# Code for restarting the runtime (that will restart colab session, all your variables will be lost)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WicMedgXzMgS"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Uczzm_zXI4"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1q2QBwkcIH2"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXtmJPYKzasz"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "UserName = getpass('GitHub User Name: ')\n",
        "UserEmail = getpass('GitHub User E-mail: ')\n",
        "RepoName = getpass('GitHub Repository Name: ')\n",
        "UserPwd = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtMP7Pjvwpm2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPPGQ3xa0dH1"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4V8x_AF1Euv"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RStVvDjfTxAk"
      },
      "source": [
        "! git clone https://github.com/{UserName}/{RepoName}.git\n",
        "\n",
        "print(\"\\n\")\n",
        "%cd /content/{RepoName}\n",
        "print(f\"\\n\\n* Current session directory is:  {os.getcwd()}\")\n",
        "print(f\"* You may refresh the session folder to access {RepoName} folder.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTydg5Xwqiu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-5uhLCk0lUJ"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra3ns1Tl0_MS"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8MWs250vtR"
      },
      "source": [
        "!git config --global user.email {UserEmail}\n",
        "!git config --global user.name {UserName}\n",
        "!git remote rm origin\n",
        "!git remote add origin https://{UserName}:{UserPwd}@github.com/{UserName}/{RepoName}.git\n",
        "\n",
        "print(f\"\\n\\n * The current Colab Session is connected to the following GitHub repo: {UserName}/{RepoName}\")\n",
        "print(\" * You can now push new files to the repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcmA1wG8AdC"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1kUQ0VIoi4c"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dafOBor8OoM"
      },
      "source": [
        "CommitMsg = \"added=cleaned-data\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkyUs70oloW"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0NCb8-L8Vr1"
      },
      "source": [
        "!git push origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVXBDTg2ouLC"
      },
      "source": [
        "### **Delete** Cloned Repo from current Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_twMc7cefGw"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf {RepoName}\n",
        "print(f\"\\n * Please refresh session folder to validate that {RepoName} folder was removed from this session.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7LEJkEZwl2K"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ELZj83tF1g"
      },
      "source": [
        "import pandas as pd\n",
        "df_raw_path = \"/content/WalkthroughProject1/inputs/datasets/WeatherAustralia_raw.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iue5e5GJ_vZg"
      },
      "source": [
        "## Quick exploration with Pandas Profiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyi3gi2-_q1j"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "ProfileReport(df, title=\"Pandas Profiling Report\",minimal=True).to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYdZHyDhu4kG"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFMfZo18cxUS"
      },
      "source": [
        "## Get Day, Month and Year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPSpZBCNc2fp"
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Day'] = df['Date'].dt.day\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df.drop(axis=1,labels=['Date'],inplace=True)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIeDzZ33c263"
      },
      "source": [
        "## Add RainfallTomorrow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv5ezghRc-uk"
      },
      "source": [
        "def AddRainfallTomorrow(df,categ_var='Location'):\n",
        "  df_final = pd.DataFrame([])\n",
        "\n",
        "  for city in df[categ_var].unique():\n",
        "    dfCity = df.query(f\"{categ_var} == '{city}'\").copy()\n",
        "    dfCity['RainfallTomorrow'] = df['Rainfall'].shift(-1)\n",
        "    df_final = df_final.append(dfCity)\n",
        "\n",
        "  return df_final\n",
        "\n",
        "df = AddRainfallTomorrow(df)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJxogPigdqG"
      },
      "source": [
        "* Are all dates in the proper sequence (with no gaps) for each cities?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRDE-p1AglGC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxoVRefhu2Bk"
      },
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcocWZkIx6nk"
      },
      "source": [
        "* Custom function to display missing data levels in a dataframe, it shows the aboslute levels, relative levels and data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9CoLqBhO7ga"
      },
      "source": [
        "def EvaluateMissingData(df):\n",
        "  missing_data_absolute = df.isnull().sum()\n",
        "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
        "  df_missing_data = (pd.DataFrame(\n",
        "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                 \"DataType\":df.dtypes}\n",
        "                                  )\n",
        "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHrzaG-ZhEKt"
      },
      "source": [
        "* Check missing data levels for initial dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxvNnLAjxCSi"
      },
      "source": [
        "EvaluateMissingData(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsFb6_NYyFgB"
      },
      "source": [
        "* Missing data levels in a visual format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1U17dNovahA"
      },
      "source": [
        "import missingno as mi\n",
        "mi.matrix(df,figsize=(20,6))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEpmPY9GHjGL"
      },
      "source": [
        "### What are the rows with missing data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heSgg7BTHmK0"
      },
      "source": [
        "df_rows_with_NA = df[df.isnull().any(axis=1)].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx8mUrDtA4co"
      },
      "source": [
        "* which cities have more missing data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSFvY5ZcA2gP"
      },
      "source": [
        "df_cities_with_NA = pd.DataFrame(data={\n",
        "                                  \"MissingDataRows\":df_rows_with_NA['Location'].sort_values().value_counts(),\n",
        "                                  \"TotalNumberOfRows\":df['Location'].sort_values().value_counts()\n",
        "                                  })\n",
        "\n",
        "df_cities_with_NA.plot(kind='bar',figsize=(20,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo-M-zjxD0Ta"
      },
      "source": [
        "* There are some cities where some variables have 100% missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iruiMFcELCh"
      },
      "source": [
        "df_cities_with_NA['Difference'] = df_cities_with_NA['TotalNumberOfRows'] - df_cities_with_NA['MissingDataRows']\n",
        "\n",
        "list_of_cities_with_NA = df_cities_with_NA.query(f\"Difference == 0\").index.to_list()\n",
        "print(f\"* There are {len(list_of_cities_with_NA)} cities where some variables have 100% of missing values. \\n\"\n",
        "      f\"* These are the cities: {list_of_cities_with_NA}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20pftRH0GLHd"
      },
      "source": [
        "for city in list_of_cities_with_NA:\n",
        "  df_aux = df.query(f\"Location == '{city}'\")\n",
        "  list_of_variables_with_100perc_missing_data = df_aux.columns[df_aux.isna().sum() / len(df_aux) == 1].to_list()\n",
        "\n",
        "  print(f\"* {city} \\n \"\n",
        "        f\"Variables with 100% missing data: {list_of_variables_with_100perc_missing_data} \\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsL8yYQEyOSt"
      },
      "source": [
        "## Dealing with Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_52ePITy6pQ"
      },
      "source": [
        "* **Strategy**\n",
        "  * It is assumed you assessed already the missing data levels, so you are aware ofthe variables to work on\n",
        "\n",
        "---\n",
        "\n",
        "* You will **iterate the steps below accross different methods**, so at the end you will have dealt with all variables with missing data\n",
        "\n",
        "  * 1 -  Select a **method**\n",
        "  * 2 - Select **variables** to apply the method\n",
        "  * 3 - Create a **separate dataframe** applying this method to the selected variables\n",
        "  * 4 - **Compare** this new dataset with initial dataset to validate/assess the effect on distribution on variables\n",
        "  * 5 - **If** you are satisfied, **apply** the selected method to the initial dataframe\n",
        "\n",
        "---\n",
        "\n",
        "* Eventually, over the steps, you will need to assess a different aspect to evaluate which method you would consider next\n",
        "  * For example, you may be in a situation where you have 3 variables with high missing data levels. You may check the correlation among them to evaluate Multicollinearity. Then you will be in a better position to select the next method\n",
        "\n",
        "  ---\n",
        "\n",
        "* Over the course, you saw multiple methods for dealing iwth missing data, like DropVariables, DropNA, Imput with mean/median/mode, Imput the most frequent item etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s11GUReTPlo"
      },
      "source": [
        "### Drop variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS19aDUsgHcO"
      },
      "source": [
        "* Method: **Drop Variables with more than 80% of missing data**\n",
        "* Select variables to apply the method\n",
        "* **just to speed up the process, we will drop variables with more than 30%, I will come back later and consider other methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-R0YuhNTP-R"
      },
      "source": [
        "variables_drop = EvaluateMissingData(df).query(f\"PercentageOfDataset > 30\").index.to_list()\n",
        "\n",
        "print(f\"* {len(variables_drop)} variables to drop \\n\\n\"\n",
        "    f\"{variables_drop}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ0vCtUUkhh0"
      },
      "source": [
        "* Create a separate dataframe applying this method to the selected variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGzxfynve1WV"
      },
      "source": [
        "df_drop_columns = df.drop(columns=variables_drop,axis=1).copy()\n",
        "\n",
        "lost_percentage = round(100- len(df_drop_columns) / len(df) *100,2) \n",
        "\n",
        "print(f\"* If I apply this method, \"\n",
        "      f\"I will lose {lost_percentage}% of all dataset, or {len(df)-len(df_drop_columns)} rows. \\n\"\n",
        "      f\"* Dataset rows before method: {len(df)} \\n\"\n",
        "      f\"* Dataset rows after method: {len(df_drop_columns)} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_R6j5sCk2Ng"
      },
      "source": [
        "* What is the effect?\n",
        "    * In this case, no effect on variables distribution, since you are not removing rows, but columns\n",
        "     * The effect is losing features that might have a relevant impact in your machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7w7JxhzlWay"
      },
      "source": [
        "* If you are statisfied, apply the method in your initial dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loKjRa4hqKZb"
      },
      "source": [
        "df = df.drop(columns=variables_drop,axis=1).copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWgcfYN4sQeY"
      },
      "source": [
        "EvaluateMissingData(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q74x5KIrRW7T"
      },
      "source": [
        "### Complete Case Analysis (\"list-wise deletion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYtnc0u4X_pS"
      },
      "source": [
        "* Method: **Remove missing observations. Rule of thumb is to consider variables with less than 5% of missing data**\n",
        "* Select variables to apply the method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2fmXi8LXycz"
      },
      "source": [
        "variables_cca = (EvaluateMissingData(df)\n",
        "                .query(\"PercentageOfDataset < 8\")\n",
        "                .index\n",
        "                .to_list()\n",
        "                )\n",
        "print(f\"* {len(variables_cca)} variables to apply Complete Case Analysis \\n\\n\"\n",
        "    f\"{variables_cca}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-m46ryMh_hZ"
      },
      "source": [
        "* Create a separate dataframe applying this method to the selected variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaJzeULTXzR5"
      },
      "source": [
        "df_cca = df.dropna(subset=variables_cca).copy()\n",
        "\n",
        "lost_percentage = round(100- len(df_cca) / len(df) *100,2) \n",
        "\n",
        "print(f\"* If I apply this method, \"\n",
        "      f\"I will lose {lost_percentage}% of all dataset, or {len(df)-len(df_cca)} rows. \\n\"\n",
        "      f\"* Dataset rows before method: {len(df)} \\n\"\n",
        "      f\"* Dataset rows after method: {len(df_cca)} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x5UklFadqys"
      },
      "source": [
        "* What is the effect?  \n",
        "  * We can plot the distribution before and after applying the method. If the distribution differs a lot, better not consider this method for that variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vADd7Ruy2J8K"
      },
      "source": [
        "* We create a custom function to evaluate. It can be used accross the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDZX-xgMZrBw"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_to_analyze):\n",
        "  sns.set(style=\"darkgrid\")\n",
        "\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns\n",
        "  flag_count=1\n",
        "\n",
        "  for var in variables_to_analyze:\n",
        "    if var in categorical_variables:\n",
        "      df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "      df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "      dfAux = pd.concat([df1, df2], axis=0)\n",
        "      # use a statistical test to inform if there is significant change\n",
        "      plt.figure(figsize=(20, 5))\n",
        "      sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"]).set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "      \n",
        "      plt.xticks(rotation=90)\n",
        "      plt.legend() \n",
        "\n",
        "    else:\n",
        "\n",
        "      # use a statistical test to inform if there is significant change\n",
        "      plt.figure(figsize=(10, 5))\n",
        "      sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\")\n",
        "      sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\").set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "      plt.legend() \n",
        "\n",
        "    plt.show()\n",
        "    flag_count+= 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qRdvx-7I4DK"
      },
      "source": [
        "DataCleaningEffect(\n",
        "    df_original = df,\n",
        "    df_cleaned = df_cca,\n",
        "    variables_to_analyze = df_cca.columns)\n",
        "\n",
        "## add variables that you applied the method: variables_cca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6V7A-gflM56"
      },
      "source": [
        "* If you are statisfied, apply the method in your dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfUd2IqJRcu6"
      },
      "source": [
        "from feature_engine.imputation import DropMissingData\n",
        "missingdata_imputer = DropMissingData(variables=variables_cca)\n",
        "missingdata_imputer.fit(df)\n",
        "df= missingdata_imputer.transform(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJLfflIRTABo"
      },
      "source": [
        "EvaluateMissingData(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jj6omTQu1_9"
      },
      "source": [
        "### Imput Median"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ36B5Iq2jZ_"
      },
      "source": [
        "* Method: **Imput Median**\n",
        "* Select variables to apply the method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpSiVuuSTWaZ"
      },
      "source": [
        "variables_median = EvaluateMissingData(df).index.to_list()\n",
        "variables_median"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvGFhdnI3bVh"
      },
      "source": [
        "* Create a separate dataframe applying this method to the selected variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8n6-NCXgA3D"
      },
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "median_imputer = MeanMedianImputer(imputation_method='median', variables=variables_median)\n",
        "median_imputer.fit(df)\n",
        "\n",
        "# transform the data\n",
        "df_median= median_imputer.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-o6_Ppv3ezV"
      },
      "source": [
        "* What is the effect?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7fnng4BgA87"
      },
      "source": [
        "DataCleaningEffect(\n",
        "    df_original = df,\n",
        "    df_cleaned = df_median,\n",
        "    variables_to_analyze =variables_median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg0fmw-g3n39"
      },
      "source": [
        "* If you are statisfied, apply the method in your initial dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac4qS95zqZmJ"
      },
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "median_imputer = MeanMedianImputer(imputation_method='median', variables=variables_median)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from config import config\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['RainTomorrow'],\n",
        "                                        test_size=config.TEST_SIZE,\n",
        "                                        random_state=config.RANDOM_STATE)\n",
        "\n",
        "# fit the imputer\n",
        "median_imputer.fit(TrainSet)\n",
        "\n",
        "# transform the data\n",
        "TrainSet, TestSet = median_imputer.transform(TrainSet) , median_imputer.transform(TestSet)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94MaQAoDqZpu"
      },
      "source": [
        "EvaluateMissingData(TrainSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYvbqLtZvjL1"
      },
      "source": [
        "EvaluateMissingData(TestSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD--GI5Jvp8h"
      },
      "source": [
        "# Save cleaned data: Train/Test sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SNWONrYwu6d"
      },
      "source": [
        "TrainSet.to_csv(\"/content/WalkthroughProject1/inputs/datasets/cleaned/TrainSetCleaned.csv\",index=False)\n",
        "TestSet.to_csv(\"/content/WalkthroughProject1/inputs/datasets/cleaned/TestSetCleaned.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frOXm8Fz8QM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# Your next notebook section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0oBmdCWb0xf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnS7v_HVb1db"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}