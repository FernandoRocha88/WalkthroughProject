{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Modeling and Evaluation - Regression.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Fit and evaluate a regression model to predict tomorrow's rainfall levels, in mm.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* content/WalkthroughProject/outputs/datasets/collection/WeatherAustralia.csv\n",
        "* instructions on which variables to use for data cleaning and feature engineering. They are found on its respectives notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Regression model\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbuGQj9lDAEo"
      },
      "source": [
        "# Install and Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAx1yVscyB3M"
      },
      "source": [
        "* You eventually will need to restart runtime when installing packages, please note cell output when installing a package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBfLDnhx-2k"
      },
      "source": [
        "! pip install feature-engine==1.0.2\n",
        "! pip install scikit-learn==0.23.2\n",
        "! pip install lazypredict==0.2.9\n",
        "! pip install pandas-profiling==2.11.0\n",
        "! pip install ppscore==1.2.0\n",
        "! pip install pingouin==0.3.12\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUFuYskeybZL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit â†’ Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHiVgPviuMx"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtPQ7EnPiuMy"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDHrzxEiuMz"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8aYwLkiuMz"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjRkDt1eOAr"
      },
      "source": [
        "* **Credentials format disclaimer**: when opening Jupyter notebooks in Colab that are hosted at GitHub, we ask you to not consider special characters in your **password**, like @ ! \" # $ % & ' ( ) * + , - . / :;< = > ? @ [\\ ]^_ ` { } | ~\n",
        "  * Otherwise it will not work properly the git push command, since the credentials are concatenated in the command: username:password@github.com/username/repo , the git push command will not work properly when these terms have special characters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_amd2ygiuM0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I2eQe-YiuM0"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfD0o1u1iuM0"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOPTqcmiuM1"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uhzcFjeiuM1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS3yEKFJiuM1"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_tFmsYgiuM2"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveMisgfiuM2"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the sessions, update the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "import uuid\n",
        "file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "print(\"\\n\\n\")\n",
        "os.remove(f\"{file_name}.txt\")\n",
        "! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpFreVRiuM3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257gMsNhiuM3"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUla5863TKyk"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzjZgWV-TMOB"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_xeleqiuM4"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpFefbLXiuM4"
      },
      "source": [
        "CommitMsg = \"update\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msFKrJ6fiuM5"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxYGf_yiuM5"
      },
      "source": [
        "!git push origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXKlJFX0iuM5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7CNgZ_TiuM6"
      },
      "source": [
        "### **Delete** Cloned Repo from current Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cobdGQGZfZG7"
      },
      "source": [
        "* Delete cloned repo and move current directory to /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UACixuaiuM6"
      },
      "source": [
        "%cd /content\n",
        "import os\n",
        "!rm -rf {os.environ['RepoName']}\n",
        "\n",
        "print(f\"\\n * Please refresh session folder to validate that {os.environ['RepoName']} folder was removed from this session.\")\n",
        "print(f\"\\n\\n* Current session directory is:  {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MKNQXhQiuM7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7DU_ekbtX8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = (pd.read_csv(\"/content/WalkthroughProject/outputs/datasets/collection/WeatherAustralia.csv\")\n",
        "      .query(\"RainTomorrow == 'Yes'\")  # subset RainTomorrow as Yes\n",
        "      .drop(labels=['RainTomorrow'],axis=1)  # target variable for classifier\n",
        "      .dropna(subset=['RainfallTomorrow'])   # drop missing data from target RainfallTomorrow\n",
        "      .dropna(subset=['RainfallToday', 'RainToday'])  # if it drops on the pipeline while training, \n",
        "                                                      # it will not remove the respective rows from the target.          \n",
        "  )\n",
        "\n",
        "\n",
        "# subset RainTomorrow as 1, label: RainfallTomorrow, features: all other variables\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt-X8SWKYLbn"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# Regressor Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kD7PZ5kZkBT"
      },
      "source": [
        "## Custom transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A96j6zLKZz7N"
      },
      "source": [
        "  * convert ['Cloud9am','Cloud3pm'] to categorical\n",
        "  * get Get Day, Month, Year, Weekday, IsWeekend from Date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_tTrXFaWSIU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Convert ['Cloud9am','Cloud3pm'] to categorical\n",
        "class ConvertToCategorical(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variables=None):\n",
        "      if not isinstance(variables, list):\n",
        "          self.variables = [variables]\n",
        "      else:\n",
        "          self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      X = X.copy()\n",
        "      for feature in self.variables:\n",
        "          X[feature] = X[feature].astype('object')\n",
        "\n",
        "      return X\n",
        "\n",
        "\n",
        "# Get Day, Month, Year, Weekday, IsWeekend from Date\n",
        "class GetFeaturesFromDate(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variable=None):\n",
        "      self.variable = variable\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      X = X.copy()\n",
        "      X[self.variable] = pd.to_datetime(X[self.variable])\n",
        "      X['Day'] = X[self.variable].dt.day\n",
        "      X['Month'] = X[self.variable].dt.month\n",
        "      X['Year'] = X[self.variable].dt.year\n",
        "      X['WeekDay']= X[self.variable].dt.weekday\n",
        "      X['IsWeekend'] = X['WeekDay'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "\n",
        "      return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZWZHhpYaDjf"
      },
      "source": [
        "## ML Pipeline: DataCleaningFeatEng, and Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9LUaOV08Su"
      },
      "source": [
        "* Reinforce we are using the raw data, therefore we need to create the pipeline with data cleaninig and feature engineering steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwcclyECARLS"
      },
      "source": [
        "### my code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv2ljHsqAQh3"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from config import config\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "class RegressorSwitcher(BaseEstimator):\n",
        "\n",
        "    def __init__(self, estimator = None ):\n",
        "        self.estimator = estimator\n",
        "\n",
        "    def fit(self, X, y=None, **kwargs):\n",
        "        self.estimator.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, y=None):\n",
        "        return self.estimator.predict(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return self.estimator.score(X, y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pipe = [\n",
        "\n",
        "    ############ Linear Models ############\n",
        "    {\n",
        "        'model__estimator': [LinearRegression()],\n",
        "        'feat_selection__estimator': [LinearRegression()],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [DecisionTreeRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'model__estimator__max_depth': [3,5,10], # [5,10,20,75,100]\n",
        "        # 'models__estimator__criterion': [\"mse\", \"mae\"], # \"friedman_mse\"\n",
        "        # 'models__estimator__max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
        "        'feat_selection__estimator': [DecisionTreeRegressor(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "    \n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "pipe_parameters_first_try = [\n",
        "\n",
        "    ############ Linear Models ############\n",
        "    {\n",
        "        'model__estimator': [LinearRegression()],\n",
        "        'feat_selection__estimator': [LinearRegression()],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [Ridge(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [Ridge(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [RidgeCV()],\n",
        "        'feat_selection__estimator': [RidgeCV()],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [Lasso(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [Lasso(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [Perceptron(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [Perceptron(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [LassoLars()],\n",
        "        'feat_selection__estimator': [LassoLars()],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [BayesianRidge()],\n",
        "        'feat_selection__estimator': [BayesianRidge()],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [SGDRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [SGDRegressor(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [ElasticNet(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [ElasticNet(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "\n",
        "\n",
        " \n",
        "    ############### Trees and Ensemble ##########\n",
        "    {\n",
        "        'model__estimator': [DecisionTreeRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [DecisionTreeRegressor(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "\n",
        "\n",
        "    {\n",
        "        'model__estimator': [RandomForestRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [RandomForestRegressor(random_state=config.RANDOM_STATE)]\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [AdaBoostRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [AdaBoostRegressor(random_state=config.RANDOM_STATE)]\n",
        "    },\n",
        "    {\n",
        "        'model__estimator': [GradientBoostingRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [GradientBoostingRegressor(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "\n",
        "    ######### XGBoost ###########\n",
        "    {\n",
        "        'model__estimator': [XGBRegressor(random_state=config.RANDOM_STATE)],\n",
        "        'feat_selection__estimator': [XGBRegressor(random_state=config.RANDOM_STATE)],\n",
        "    },\n",
        "\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KS7_98cKDqW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvkzdtlrASgO"
      },
      "source": [
        "### internet code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr0kimOaAjL6"
      },
      "source": [
        "### ml pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6keis6ao8LA"
      },
      "source": [
        "from config import config\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import DropMissingData\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.transformation import (LogTransformer,\n",
        "                                           ReciprocalTransformer,\n",
        "                                           PowerTransformer,\n",
        "                                           BoxCoxTransformer,\n",
        "                                           YeoJohnsonTransformer)\n",
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "from feature_engine.encoding import RareLabelEncoder,OrdinalEncoder\n",
        "\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "\n",
        "  pipeline_base = Pipeline(\n",
        "      [\n",
        "      ###### Data Cleaning ######\n",
        "      (\"ConvertToCategorical\",ConvertToCategorical(variables = ['Cloud9am','Cloud3pm'])\n",
        "      ),\n",
        "\n",
        "      (\"GetFeaturesFromDate\",GetFeaturesFromDate(variable = 'Date')\n",
        "      ),\n",
        "       \n",
        "      \n",
        "      # drop rows when load data, not in the pipeline\n",
        "      # if it drops on the pipeline while training, it will not remove the respective rows from the target.\n",
        "      # (\"DropMissingData\",DropMissingData(variables = ['RainfallToday', 'RainToday'])\n",
        "      # ),\n",
        "\n",
        "      (\"CategoricalImputer\",CategoricalImputer(variables = ['WindDir9am', 'WindGustDir', 'WindDir3pm','Cloud3pm'],\n",
        "                                               imputation_method='missing',fill_value='Missing')\n",
        "      ),\n",
        "\n",
        "      (\"MedianImputer\",MeanMedianImputer(imputation_method='median',\n",
        "                                         variables=['Pressure3pm', 'Pressure9am','WindGustSpeed',\n",
        "                                                  'Humidity3pm', 'Temp3pm', 'WindSpeed3pm',\n",
        "                                                  'Humidity9am','WindSpeed9am','Temp9am',\n",
        "                                                  'MaxTemp','RainfallToday','Sunshine']\n",
        "                                          )\n",
        "      ),\n",
        "\n",
        "      (\"MeanImputer\",MeanMedianImputer(imputation_method='mean',variables=['MinTemp'])\n",
        "      ),\n",
        "       \n",
        "      (\"DropFeatures\",DropFeatures(features_to_drop = ['Evaporation','Cloud9am','Date',\n",
        "                                                       'Sunshine','RainfallToday'])\n",
        "      ),  \n",
        "\n",
        "      ###### Feature Engineering ######\n",
        "       \n",
        "      (\"RareLabelEncoder_tol5\",RareLabelEncoder(tol=0.05, n_categories=2, variables=['WindDir3pm'])\n",
        "      ),\n",
        "       \n",
        "      (\"RareLabelEncoder_tol7\",RareLabelEncoder(tol=0.06, n_categories=2, variables=['State'])\n",
        "      ),\n",
        "       \n",
        "\n",
        "      (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                  variables = ['Location','WindGustDir','WindDir9am',\n",
        "                                                               'WindDir3pm','State','Cloud3pm','RainToday'])\n",
        "      ),\n",
        "\n",
        "\n",
        "      # (\"Winsorizer_iqr\",Winsorizer(capping_method='iqr',tail='both', fold=3,variables = ['RainfallToday'])\n",
        "      # ),\n",
        "\n",
        "\n",
        "      (\"PowerTransformer\",PowerTransformer(variables = ['WindSpeed3pm','Humidity3pm'])\n",
        "      ),\n",
        "\n",
        "      (\"YeoJohnsonTransformer\",YeoJohnsonTransformer(variables=['WindGustSpeed','WindSpeed9am','Humidity9am',\n",
        "                                                                # 'RainfallToday'\n",
        "                                                                ])\n",
        "      ),\n",
        "\n",
        "      (\"EqualFrequencyDiscretiser\",EqualFrequencyDiscretiser(q=5,variables = ['Latitude','Longitude'])\n",
        "      ),\n",
        "\n",
        "    ]\n",
        "  )\n",
        "  return pipeline_base\n",
        "\n",
        "\n",
        "def PipelineRegressor():\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "\n",
        "  pipe.steps.append(\n",
        "      [\"scaler\",StandardScaler()]\n",
        "      )\n",
        "\n",
        "  pipe.steps.append(\n",
        "      [\"feat_selection\",SelectFromModel(RegressorSwitcher()) ]\n",
        "      )\n",
        " \n",
        "  pipe.steps.append(\n",
        "      [\"model\",RegressorSwitcher()]\n",
        "      )\n",
        "  \n",
        "  return pipe\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWTrFyxZWVar"
      },
      "source": [
        "* Helper for Hyperparameter Optmization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpTcVDtQ5RMc"
      },
      "source": [
        "def PipelineHelper(model):\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        "  pipe.steps.append([\"scaler\",StandardScaler()])\n",
        "  pipe.steps.append([\"feat_selection\",SelectFromModel(model)])\n",
        "  pipe.steps.append([\"model\",model])\n",
        "  \n",
        "  return pipe\n",
        "\n",
        "\n",
        "class EstimatorSelectionHelper:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        # if not set(models.keys()).issubset(set(params.keys())):\n",
        "        #     missing_params = list(set(models.keys()) - set(params.keys()))\n",
        "        #     raise ValueError(f\"Some estimators are missing parameters: {missing_params}\")\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineHelper(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit,\n",
        "                              return_train_score=True)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaMLXQrbAqQb"
      },
      "source": [
        "models_search = {\n",
        "    # 'LinearRegression': LinearRegression(),\n",
        "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=config.RANDOM_STATE),\n",
        "    # 'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
        "    'XGBRegressor': XGBRegressor()\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    # 'LinearRegression': { 'n_estimators': [16, 32] },\n",
        "    'DecisionTreeRegressor': { 'model__max_depth': [2,10] },\n",
        "    # 'GradientBoostingRegressor':  { 'n_estimators': [16, 32] },\n",
        "    'XGBRegressor': { 'model__n_estimators': [16, 32], 'model__learning_rate': [0.8, 1.0] },\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvwabO0JsmYW"
      },
      "source": [
        "# Features Profile before hitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qufL2HWrF8ig"
      },
      "source": [
        "### Supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Zy_MglsmYo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr_pps(df,threshold):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=(20,12))\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                        mask=mask,cmap='rocket_r', annot_kws={\"size\": 8})\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr_pps(df=df_corr_spearman, threshold=CorrThreshold)\n",
        "  \n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr_pps(df=df_corr_pearson, threshold=CorrThreshold)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_corr_pps(df=pps_matrix,threshold=PPS_Threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VlnCBsSdhc-"
      },
      "source": [
        "### Transform the data before hitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1Qr3Xxmdg-D"
      },
      "source": [
        "FeaturesTrainSet = df.copy()#.drop(['RainfallTomorrow'],axis=1).copy()\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(FeaturesTrainSet)\n",
        "                                        .columns)\n",
        "\n",
        "\n",
        "pipeline_before_model = Pipeline(PipelineRegressor().steps[:-2])\n",
        "df_before_hitting_model = pd.DataFrame(data = pipeline_before_model.fit_transform(FeaturesTrainSet),\n",
        "                                       columns = columns_after_data_cleaning_feat_eng)\n",
        "\n",
        "print(df_before_hitting_model.shape)\n",
        "df_before_hitting_model.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab5lQQBKcAeZ"
      },
      "source": [
        "### Data Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ex7eUUzcAmF"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df_before_hitting_model, minimal=True)\n",
        "profile.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryNo1VnXSK9K"
      },
      "source": [
        "### Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Z4SXf6GbED"
      },
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df_before_hitting_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-0L4PiSPEK"
      },
      "source": [
        "* Display at Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioE3yuC4Q7QK"
      },
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,\n",
        "                  CorrThreshold=0.6, PPS_Threshold=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMbLiVQkD3Y"
      },
      "source": [
        "# Lazy Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIiC8A3dkPQA"
      },
      "source": [
        "* Transform the data using pipeline, except last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjKHFaC6kPYW"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline_lazy = Pipeline(PipelineRegressor().steps[:-2])\n",
        "columns_after_data_cleaning_feat_eng = pipeline_lazy.fit_transform(df).columns\n",
        "columns_after_data_cleaning_feat_eng\n",
        "\n",
        "pipeline_lazy = Pipeline(PipelineRegressor().steps[:-1])\n",
        "df_lazy = pipeline_lazy.fit_transform(df)\n",
        "df_lazy = pd.DataFrame(data = df_lazy,\n",
        "                       columns = columns_after_data_cleaning_feat_eng)\n",
        "\n",
        "df_lazy = df_lazy.sample(frac=0.7, random_state=config.RANDOM_STATE)\n",
        "\n",
        "df_lazy.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUWVwx6akLzR"
      },
      "source": [
        "* Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiRtbU31kL84"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_lazy.drop(['RainfallTomorrow'],axis=1),\n",
        "                                    df_lazy['RainfallTomorrow'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBmumDTakHco"
      },
      "source": [
        "* Fit Lazy Predict models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIr5aPEokHiE"
      },
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "reg = LazyRegressor(ignore_warnings=False, predictions=False, random_state=config.RANDOM_STATE,regressors='all')\n",
        "models ,predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "# remove these\n",
        "# 'KernelRidge', 'NuSVR', 'GaussianProcessRegressor','SVR','MLPRegressor'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAf5iLjitx-0"
      },
      "source": [
        "* Check performance summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4uBw1mxnJIO"
      },
      "source": [
        "models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQBjAlRsHhU4"
      },
      "source": [
        "# Modeling - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpxaylKk-6CQ"
      },
      "source": [
        "* Quick recap in our raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfKHc63v-6Zm"
      },
      "source": [
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD6B3CuhiDMT"
      },
      "source": [
        "* Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFzP2iGiIk1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# df = df.sample(frac=0.1)\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['RainfallTomorrow'],axis=1),\n",
        "                                    df['RainfallTomorrow'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE\n",
        "                                    )\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j285uIq1f3h3"
      },
      "source": [
        "### Target Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0IYJz0uf2CT"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pingouin as pg\n",
        "\n",
        "def Target_DistributionAndStats(y_train,y_test):\n",
        "\n",
        "  figure, ax = plt.subplots(nrows=1, ncols=2,figsize=(15,4))\n",
        "  sns.histplot(x=y_train, kde=True,ax=ax[0]).set(title='y train')\n",
        "  sns.histplot(x=y_test, kde=True,ax=ax[1]).set(title='y test')\n",
        "  plt.show();\n",
        "\n",
        "  print(\"\\n* Train set - normality test: \\n\", pg.normality(y_train,method='shapiro',alpha=0.05))\n",
        "  print(\"\\n* Train set - target descriptive stats: \\n\", y_train.describe().round(3).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4TsdEhkhlht"
      },
      "source": [
        "Target_DistributionAndStats(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOckbv6Wa4Gy"
      },
      "source": [
        "#### Target Capping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OX2ch76madF"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdxAc7KFkfCl"
      },
      "source": [
        "from feature_engine.outliers import ArbitraryOutlierCapper\n",
        "capper = ArbitraryOutlierCapper(max_capping_dict={'RainfallTomorrow': 50})\n",
        "\n",
        "y_train = capper.fit_transform(pd.DataFrame(data=y_train)).iloc[:,0]\n",
        "y_test = capper.transform(pd.DataFrame(data=y_test)).iloc[:,0]\n",
        "\n",
        "Target_DistributionAndStats(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUSDkpgSnNed"
      },
      "source": [
        "#### Target Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTCBJMua4QS"
      },
      "source": [
        "import sklearn.preprocessing\n",
        "target_transformer = sklearn.preprocessing.PowerTransformer(method='box-cox',standardize=True)\n",
        "\n",
        "y_train = target_transformer.fit_transform(y_train.to_frame())      #.ravel()\n",
        "y_train= pd.Series(y_train.reshape(-1),name='RainfallTomorrow')\n",
        "\n",
        "y_test = target_transformer.transform(y_test.to_frame())          #.ravel()\n",
        "y_test= pd.Series(y_test.reshape(-1),name='RainfallTomorrow')\n",
        "\n",
        "# target_transformer.inverse_transform(y_test.values.reshape(-1,1)) # test for inverse_transform\n",
        "Target_DistributionAndStats(y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znXl8PeYpEIy"
      },
      "source": [
        "#### Convert Target to Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7p4_lGpERm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-15-sWUST6XX"
      },
      "source": [
        "### GridSearch CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_q-ru92GiBb"
      },
      "source": [
        "helper1 = EstimatorSelectionHelper(models=models1, params=params1)\n",
        "helper1.fit(X_train, y_train, scoring='r2', n_jobs=-1,cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k04icRgmGukF"
      },
      "source": [
        "helper1.score_summary(sort_by='max_score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLkUcA7riJD0"
      },
      "source": [
        "* Create Raw Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imwlDdi6iJK-"
      },
      "source": [
        "pipeline_regressor = PipelineRegressor()\n",
        "pipeline_regressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqUZmy5EfhLw"
      },
      "source": [
        "* Set model's parameters and train the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zULnj1IU6n-0"
      },
      "source": [
        "pipe_parameters_first_try\n",
        "\n",
        "# GradientBoostingRegressor(random_state=0)\n",
        "# 10\tRandomForestRegressor(random_state=0)\n",
        "# 13\tXGBRegressor(base_score=None, booster=None, co...\n",
        "# 7\tSGDRegressor(random_state=0)\n",
        "# 1\tRidge(random_state=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVndkThEsOS"
      },
      "source": [
        "# _parameters = {\n",
        "#     'model__learning_rate': [0.1], #  [0.01,0.1,0.2],\n",
        "#     'model__n_estimators':[80], # [80,150,500],\n",
        "#     'model__max_depth':  [None] # [None,3,10]\n",
        "# }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOsOsPbT6gN"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "_pipe = GridSearchCV(\n",
        "\t\testimator = pipeline_regressor,\n",
        "\t\tparam_grid = pipe_parameters_first_try, \n",
        "\t\tcv=5,n_jobs=-1,verbose=2,\n",
        "    scoring = \"r2\")\n",
        "\n",
        "_pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPFBltLvEWuY"
      },
      "source": [
        "* results list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZHvzSEnCjRb"
      },
      "source": [
        " pd.DataFrame.from_dict(_pipe.cv_results_, orient='columns').sort_values(by=['rank_test_score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjYRnXYfxVT"
      },
      "source": [
        "* Best parameter's arrangment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QPWZ6ajUhmf"
      },
      "source": [
        "best_regressor_pipeline = _pipe.best_estimator_\n",
        "_pipe.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJjjBGL4bLG1"
      },
      "source": [
        "* Most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5jfRQLbPEY"
      },
      "source": [
        "# after data cleaning and feat engine, the feature space changes\n",
        "columns_after_data_cleaning_feat_eng = (PipelineDataCleaningAndFeatureEngineering()\n",
        "                                        .fit_transform(X_train)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].to_list()\n",
        "print(f\"* These are the {len(best_features)} most important features. \"\n",
        "      f\"The model was trained on them: \\n{best_features}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtmFP_Ulpnd"
      },
      "source": [
        "# Regressor Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da8GYQBCinpM"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJPFLoTciOI5"
      },
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error \n",
        "import numpy as np\n",
        "\n",
        "def model_score_train_test_set(X_train, y_train, X_test, y_test,pipeline):\n",
        "\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tPredictionEvaluation(X_train,y_train,pipeline)\n",
        "\n",
        "\tprint(\"* Test Set\")\n",
        "\tPredictionEvaluation(X_test,y_test,pipeline)\n",
        "\n",
        "\n",
        "\n",
        "def PredictionEvaluation(X,y,pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  print('R2 Score:', r2_score(y, prediction).round(3))  \n",
        "  print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))  \n",
        "  print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))  \n",
        "  print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y, prediction)).round(3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,pipeline):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "  Plot_Prediction_vs_Actual(y_train,pred_train,y_test, pred_test)\n",
        "\n",
        "\n",
        "\n",
        "def Plot_Prediction_vs_Actual(TrainActual,TrainPred,TestActual,TestPred):\n",
        "\n",
        "  fig = make_subplots(rows=1, cols=2,\n",
        "      subplot_titles=(\"Train Set\", \"Test Set\")\n",
        "      )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TrainActual,\n",
        "          y=TrainPred,\n",
        "          marker=dict(opacity=0.3),\n",
        "          mode='markers',\n",
        "          name='Prediction x Actual'),\n",
        "      row=1, col=1)\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TrainActual,\n",
        "          y=TrainActual,\n",
        "          mode='lines',\n",
        "          name='Accurate Prediction Reference'),\n",
        "      row=1, col=1)\n",
        "\n",
        "\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TestActual,\n",
        "          y=TestPred,\n",
        "          marker=dict(opacity=0.3),\n",
        "          mode='markers',\n",
        "          name='Prediction x Actual'),\n",
        "      row=1, col=2)\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(\n",
        "          x=TestActual,\n",
        "          y=TestActual,\n",
        "          mode='lines',\n",
        "          name='Accurate Prediction Reference'),\n",
        "      row=1, col=2)\n",
        "\n",
        "\n",
        "  # Update xaxis and yaxis properties\n",
        "  fig.update_xaxes(title_text=\"Actual\", row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"Actual\", row=1, col=2)\n",
        "  fig.update_yaxes(title_text=\"Prediction\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\" \", row=1, col=2)\n",
        "\n",
        "\n",
        "\n",
        "  fig.update_layout(\n",
        "      title=' ',\n",
        "      plot_bgcolor='rgba(236,236,236,1)',\n",
        "      showlegend=False\n",
        "      )\n",
        "  fig.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--CTB-H7iqzE"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QeE9he9PIwA"
      },
      "source": [
        "model_score_train_test_set(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "PredictionVsActual_TrainTestSets(X_train, y_train, X_test, y_test,best_regressor_pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwQ5_7rlii-Q"
      },
      "source": [
        "# TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV3gBxwKilA_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK8LJ9AViptX"
      },
      "source": [
        "def CreateTensorFlowModel():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(19,activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='mse')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKAp3TMqranM"
      },
      "source": [
        "# pipeline_before_model =  PipelineDataCleaningAndFeatureEngineering()\n",
        "# X_train_tf = pipeline_before_model.fit_transform(X_train)\n",
        "# X_train_tf = pipeline_before_model.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy_HTrh5i1Pz"
      },
      "source": [
        "model = CreateTensorFlowModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDpunWf6sDkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp_p_9i4izyP"
      },
      "source": [
        "model.fit(x=X_train_tf,y=y_train.values,\n",
        "          validation_data=(X_train_tf,y_test.values),\n",
        "          epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU_-bkeNi5A8"
      },
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOYpcvuRj8FU"
      },
      "source": [
        "losses.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}