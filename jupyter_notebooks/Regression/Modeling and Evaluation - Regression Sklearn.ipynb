{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Modeling and Evaluation - Regression Sklearn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Fit and evaluate a regression model to predict tomorrow's rainfall levels, in mm.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* content/WalkthroughProject/outputs/datasets/collection/WeatherAustralia.csv\n",
        "* instructions on which variables to use for data cleaning and feature engineering. They are found on its respectives notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Regression model\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbuGQj9lDAEo"
      },
      "source": [
        "# Install and Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAx1yVscyB3M"
      },
      "source": [
        "* You eventually will need to restart runtime when installing packages, please note cell output when installing a package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBfLDnhx-2k"
      },
      "source": [
        "! pip install feature-engine==1.0.2\n",
        "! pip install scikit-learn==0.23.2\n",
        "! pip install yellowbrick==1.2\n",
        "! pip install lazypredict==0.2.9\n",
        "\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUFuYskeybZL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit → Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHiVgPviuMx"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtPQ7EnPiuMy"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDHrzxEiuMz"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8aYwLkiuMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd807db-263b-40ac-fa5b-30ff805904d7"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Thanks for inserting your credentials!\n",
            "* You may now Clone your Repo to this Session, then Connect this Session to your Repo.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjRkDt1eOAr"
      },
      "source": [
        "* **Credentials format disclaimer**: when opening Jupyter notebooks in Colab that are hosted at GitHub, we ask you to not consider special characters in your **password**, like @ ! \" # $ % & ' ( ) * + , - . / :;< = > ? @ [\\ ]^_ ` { } | ~\n",
        "  * Otherwise it will not work properly the git push command, since the credentials are concatenated in the command: username:password@github.com/username/repo , the git push command will not work properly when these terms have special characters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_amd2ygiuM0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I2eQe-YiuM0"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfD0o1u1iuM0"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOPTqcmiuM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186692f4-b1f7-4b57-a3b5-2592746dc53e"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'WalkthroughProject' already exists and is not an empty directory.\n",
            "\n",
            "\n",
            "/content/WalkthroughProject\n",
            "\n",
            "\n",
            "* Current session directory is:/content/WalkthroughProject\n",
            "* You may refresh the session folder to access WalkthroughProject folder.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uhzcFjeiuM1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS3yEKFJiuM1"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_tFmsYgiuM2"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveMisgfiuM2"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the sessions, update the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "# import uuid\n",
        "# file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "# with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "# print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "# ! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "# print(\"\\n\\n\")\n",
        "# os.remove(f\"{file_name}.txt\")\n",
        "# ! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpFreVRiuM3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257gMsNhiuM3"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUla5863TKyk"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzjZgWV-TMOB"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_xeleqiuM4"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpFefbLXiuM4"
      },
      "source": [
        "CommitMsg = \"update\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msFKrJ6fiuM5"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxYGf_yiuM5"
      },
      "source": [
        "!git push origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXKlJFX0iuM5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7CNgZ_TiuM6"
      },
      "source": [
        "### **Delete** Cloned Repo from current Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cobdGQGZfZG7"
      },
      "source": [
        "* Delete cloned repo and move current directory to /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UACixuaiuM6"
      },
      "source": [
        "%cd /content\n",
        "import os\n",
        "!rm -rf {os.environ['RepoName']}\n",
        "\n",
        "print(f\"\\n * Please refresh session folder to validate that {os.environ['RepoName']} folder was removed from this session.\")\n",
        "print(f\"\\n\\n* Current session directory is:  {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MKNQXhQiuM7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7DU_ekbtX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7225cded-cd21-4ac3-d1a8-3d7ff736d303"
      },
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"/content/WalkthroughProject/outputs/datasets/collection/WeatherAustralia.csv\")\n",
        "      .query(\"RainTomorrow == 'Yes'\")  # subset RainTomorrow as Yes\n",
        "      .drop(labels=['RainTomorrow'],axis=1)\n",
        "      .dropna(subset=['RainfallTomorrow'])   # drop missing data from target RainfallTomorrow\n",
        "  )\n",
        "\n",
        "\n",
        "# subset RainTomorrow as 1, label: RainfallTomorrow, features: all other variables\n",
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 31838 entries, 8 to 145393\n",
            "Data columns (total 26 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Date              31838 non-null  object \n",
            " 1   Location          31838 non-null  object \n",
            " 2   MinTemp           31663 non-null  float64\n",
            " 3   MaxTemp           31783 non-null  float64\n",
            " 4   RainfallToday     31162 non-null  float64\n",
            " 5   Evaporation       17836 non-null  float64\n",
            " 6   Sunshine          16801 non-null  float64\n",
            " 7   WindGustDir       29374 non-null  object \n",
            " 8   WindGustSpeed     29399 non-null  float64\n",
            " 9   WindDir9am        29921 non-null  object \n",
            " 10  WindDir3pm        30786 non-null  object \n",
            " 11  WindSpeed9am      31498 non-null  float64\n",
            " 12  WindSpeed3pm      31155 non-null  float64\n",
            " 13  Humidity9am       31304 non-null  float64\n",
            " 14  Humidity3pm       30874 non-null  float64\n",
            " 15  Pressure9am       28740 non-null  float64\n",
            " 16  Pressure3pm       28730 non-null  float64\n",
            " 17  Cloud9am          20600 non-null  float64\n",
            " 18  Cloud3pm          20266 non-null  float64\n",
            " 19  Temp9am           31540 non-null  float64\n",
            " 20  Temp3pm           31096 non-null  float64\n",
            " 21  RainToday         31162 non-null  object \n",
            " 22  RainfallTomorrow  31838 non-null  float64\n",
            " 23  Latitude          31838 non-null  float64\n",
            " 24  Longitude         31838 non-null  float64\n",
            " 25  State             31838 non-null  object \n",
            "dtypes: float64(19), object(7)\n",
            "memory usage: 6.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# Regressor Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kD7PZ5kZkBT"
      },
      "source": [
        "## Custom transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A96j6zLKZz7N"
      },
      "source": [
        "  * convert ['Cloud9am','Cloud3pm'] to categorical\n",
        "  * get Get Day, Month, Year, Weekday, IsWeekend from Date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_tTrXFaWSIU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Convert ['Cloud9am','Cloud3pm'] to categorical\n",
        "class ConvertToCategorical(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variables=None):\n",
        "      if not isinstance(variables, list):\n",
        "          self.variables = [variables]\n",
        "      else:\n",
        "          self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      X = X.copy()\n",
        "      for feature in self.variables:\n",
        "          X[feature] = X[feature].astype('object')\n",
        "\n",
        "      return X\n",
        "\n",
        "\n",
        "# Get Day, Month, Year, Weekday, IsWeekend from Date\n",
        "class GetFeaturesFromDate(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variable=None):\n",
        "      self.variable = variable\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      X = X.copy()\n",
        "      X[self.variable] = pd.to_datetime(X[self.variable])\n",
        "      X['Day'] = X[self.variable].dt.day\n",
        "      X['Month'] = X[self.variable].dt.month\n",
        "      X['Year'] = X[self.variable].dt.year\n",
        "      X['WeekDay']= X[self.variable].dt.weekday\n",
        "      X['IsWeekend'] = X['WeekDay'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "\n",
        "      return X\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZWZHhpYaDjf"
      },
      "source": [
        "## ML Pipeline: DataCleaningFeatEng, and Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6keis6ao8LA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82b2fe5-9796-4810-a47b-00a3d53271d8"
      },
      "source": [
        "from config import config\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.imputation import AddMissingIndicator\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import DropMissingData\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.transformation import (LogTransformer,\n",
        "                                           ReciprocalTransformer,\n",
        "                                           PowerTransformer,\n",
        "                                           BoxCoxTransformer,\n",
        "                                           YeoJohnsonTransformer)\n",
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "from feature_engine.encoding import RareLabelEncoder\n",
        "from feature_engine.encoding import CountFrequencyEncoder\n",
        "\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "\n",
        "  pipeline_base = Pipeline(\n",
        "      [\n",
        "      ### Data Cleaning\n",
        "      (\"ConvertToCategorical\",ConvertToCategorical(variables = ['Cloud9am','Cloud3pm'])\n",
        "      ),\n",
        "\n",
        "      (\"GetFeaturesFromDate\",GetFeaturesFromDate(variable= 'Date')\n",
        "      ),\n",
        "       \n",
        "      (\"AddMissingIndicator\",AddMissingIndicator(variables= ['Sunshine', 'Evaporation', 'Cloud3pm',\n",
        "                                                             'Cloud9am', 'Pressure9am', 'Pressure3pm',\n",
        "                                                             'WindDir9am', 'WindGustDir', 'WindGustSpeed',\n",
        "                                                             'Humidity3pm', 'WindDir3pm', 'Temp3pm',\n",
        "                                                             'RainfallToday', 'RainToday',\n",
        "                                                             'WindSpeed3pm', 'Humidity9am','Temp9am',\n",
        "                                                             'WindSpeed9am', 'MinTemp','MaxTemp'])\n",
        "      ),\n",
        "\n",
        "      (\"DropFeatures\",DropFeatures(features_to_drop = ['Sunshine','Evaporation','Cloud9am','Date'])\n",
        "      ),                                         ##########dont drop sunshine\n",
        "\n",
        "      (\"DropMissingData\",DropMissingData(variables =['RainfallToday', 'RainToday'])\n",
        "      ),\n",
        "\n",
        "      (\"CategoricalImputer\",CategoricalImputer(variables=['WindDir9am', 'WindGustDir', 'WindDir3pm','Cloud3pm'],\n",
        "                                                imputation_method='missing',fill_value='Missing')\n",
        "      ),\n",
        "\n",
        "      (\"MedianImputer\",MeanMedianImputer(imputation_method='median',\n",
        "                                          variables=['Pressure3pm', 'Pressure9am','WindGustSpeed',\n",
        "                                                    'Humidity3pm', 'Temp3pm', 'WindSpeed3pm', 'Humidity9am',\n",
        "                                                    'WindSpeed9am','Temp9am','MaxTemp',\n",
        "                                                     'RainfallToday']\n",
        "                                          )\n",
        "      ),\n",
        "\n",
        "      (\"MeanImputer\",MeanMedianImputer(imputation_method='mean',variables=['MinTemp'])\n",
        "      ),\n",
        "\n",
        "      ### Feature Engineering\n",
        "\n",
        "      (\"Winsorizer_iqr\",Winsorizer(capping_method='iqr',tail='both', fold=3,variables = ['RainfallToday'])\n",
        "      ),\n",
        "\n",
        "\n",
        "      (\"PowerTransformer\",PowerTransformer(variables = ['WindSpeed3pm','Humidity3pm'])\n",
        "      ),\n",
        "\n",
        "      (\"YeoJohnsonTransformer\",YeoJohnsonTransformer(variables=['RainfallToday','WindGustSpeed',\n",
        "                                                                'WindSpeed9am','Humidity9am'])\n",
        "      ),\n",
        "\n",
        "      (\"EqualFrequencyDiscretiser\",EqualFrequencyDiscretiser(q=5,variables = ['Latitude','Longitude' ])\n",
        "      ),\n",
        "\n",
        "      (\"RareLabelEncoder_tol5\",RareLabelEncoder(tol=0.05, n_categories=2, variables=['WindDir3pm'])\n",
        "      ),\n",
        "\n",
        "      (\"RareLabelEncoder_tol7\",RareLabelEncoder(tol=0.06, n_categories=2, variables=['State'])\n",
        "      ),\n",
        "\n",
        "      (\"CountEncoder\",CountFrequencyEncoder(encoding_method='count',\n",
        "                                            variables = ['Location','WindGustDir','WindDir9am',\n",
        "                                                          'WindDir3pm','State','Cloud3pm',\n",
        "                                                          'RainToday'])\n",
        "      )\n",
        "\n",
        "    ]\n",
        "  )\n",
        "  return pipeline_base\n",
        "\n",
        "\n",
        "def PipelineRegressor():\n",
        "  pipe = PipelineDataCleaningAndFeatureEngineering()\n",
        " \n",
        "  pipe.steps.append([\n",
        "                     \"scaler\",StandardScaler()\n",
        "                     ])\n",
        "  \n",
        "  pipe.steps.append([\n",
        "                     \"model\",DecisionTreeRegressor(random_state=config.RANDOM_STATE)\n",
        "                     ])\n",
        "  return pipe\n",
        "\n",
        "\n",
        "\n",
        "PipelineRegressor()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ConvertToCategorical',\n",
              "                 ConvertToCategorical(variables=['Cloud9am', 'Cloud3pm'])),\n",
              "                ('GetFeaturesFromDate', GetFeaturesFromDate(variable='Date')),\n",
              "                ('AddMissingIndicator',\n",
              "                 AddMissingIndicator(variables=['Sunshine', 'Evaporation',\n",
              "                                                'Cloud3pm', 'Cloud9am',\n",
              "                                                'Pressure9am', 'Pressure3pm',\n",
              "                                                'WindDir9am', 'WindGustDir',\n",
              "                                                'WindGustSpeed', 'Humidity3pm',\n",
              "                                                'WindD...\n",
              "                 RareLabelEncoder(n_categories=2, variables=['WindDir3pm'])),\n",
              "                ('RareLabelEncoder_tol7',\n",
              "                 RareLabelEncoder(n_categories=2, tol=0.06,\n",
              "                                  variables=['State'])),\n",
              "                ('CountEncoder',\n",
              "                 CountFrequencyEncoder(variables=['Location', 'WindGustDir',\n",
              "                                                  'WindDir9am', 'WindDir3pm',\n",
              "                                                  'State', 'Cloud3pm',\n",
              "                                                  'RainToday'])),\n",
              "                ['scaler', StandardScaler()],\n",
              "                ['model', DecisionTreeRegressor(random_state=0)]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMbLiVQkD3Y"
      },
      "source": [
        "# Lazy Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIiC8A3dkPQA"
      },
      "source": [
        "* Transform the data using pipeline, except last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjKHFaC6kPYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef0b34b-7aa9-42c6-e954-7536f59b5ee8"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline_lazy = Pipeline(PipelineRegressor().steps[:-2])\n",
        "columns_after_data_cleaning_feat_eng = pipeline_lazy.fit_transform(df).columns\n",
        "columns_after_data_cleaning_feat_eng\n",
        "\n",
        "pipeline_lazy = Pipeline(PipelineRegressor().steps[:-1])\n",
        "df_lazy = pipeline_lazy.fit_transform(df)\n",
        "df_lazy = pd.DataFrame(data = df_lazy,\n",
        "                       columns = columns_after_data_cleaning_feat_eng)\n",
        "\n",
        "df_lazy = df_lazy.sample(frac=0.4, random_state=config.RANDOM_STATE)\n",
        "\n",
        "df_lazy.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12465, 47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUWVwx6akLzR"
      },
      "source": [
        "* Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiRtbU31kL84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7c5e7a-de24-4afc-90b0-552c578ec96c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_lazy.drop(['RainfallTomorrow'],axis=1),\n",
        "                                    df_lazy['RainfallTomorrow'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9972, 46) (2493, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBmumDTakHco"
      },
      "source": [
        "* Fit Lazy Predict models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIr5aPEokHiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112b60e2-f022-49c2-dbdc-e899e15d6e12"
      },
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "reg = LazyRegressor(ignore_warnings=False, predictions=False, random_state=config.RANDOM_STATE)\n",
        "models ,predictions = reg.fit(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 9/42 [00:10<01:02,  1.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GammaRegressor model failed to execute\n",
            "Some value(s) of y are out of the valid range for family GammaDistribution\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 30/42 [01:23<00:37,  3.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PoissonRegressor model failed to execute\n",
            "Some value(s) of y are out of the valid range for family PoissonDistribution\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [01:49<00:00,  2.61s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAf5iLjitx-0"
      },
      "source": [
        "* Check performance summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4uBw1mxnJIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ef2388d-9a16-4c78-ffa1-491e3aff6d65"
      },
      "source": [
        "models"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adjusted R-Squared</th>\n",
              "      <th>R-Squared</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GradientBoostingRegressor</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.85</td>\n",
              "      <td>2.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMRegressor</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HistGradientBoostingRegressor</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesRegressor</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.86</td>\n",
              "      <td>7.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.87</td>\n",
              "      <td>12.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBRegressor</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingRegressor</th>\n",
              "      <td>0.16</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLarsIC</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNetCV</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BayesianRidge</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLarsCV</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KernelRidge</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>12.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransformedTargetRegressor</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDRegressor</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVR</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.92</td>\n",
              "      <td>12.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LarsCV</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.93</td>\n",
              "      <td>11.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lars</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OrthogonalMatchingPursuitCV</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OrthogonalMatchingPursuit</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TweedieRegressor</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GeneralizedLinearRegressor</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsRegressor</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.96</td>\n",
              "      <td>2.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPRegressor</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.98</td>\n",
              "      <td>10.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HuberRegressor</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianProcessRegressor</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.99</td>\n",
              "      <td>29.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVR</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLars</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyRegressor</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RANSACRegressor</th>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeRegressor</th>\n",
              "      <td>-0.48</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveRegressor</th>\n",
              "      <td>-0.87</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeRegressor</th>\n",
              "      <td>-0.98</td>\n",
              "      <td>-0.94</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostRegressor</th>\n",
              "      <td>-1.70</td>\n",
              "      <td>-1.65</td>\n",
              "      <td>1.64</td>\n",
              "      <td>1.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
              "Model                                                                         \n",
              "GradientBoostingRegressor                    0.29       0.30  0.85        2.57\n",
              "LGBMRegressor                                0.26       0.28  0.86        0.38\n",
              "HistGradientBoostingRegressor                0.26       0.27  0.86        1.06\n",
              "ExtraTreesRegressor                          0.25       0.27  0.86        7.07\n",
              "RandomForestRegressor                        0.25       0.26  0.87       12.31\n",
              "XGBRegressor                                 0.19       0.20  0.90        1.54\n",
              "BaggingRegressor                             0.16       0.18  0.92        1.29\n",
              "LassoLarsIC                                  0.15       0.17  0.92        0.05\n",
              "ElasticNetCV                                 0.15       0.17  0.92        0.51\n",
              "LassoCV                                      0.15       0.17  0.92        0.57\n",
              "BayesianRidge                                0.15       0.17  0.92        0.06\n",
              "LassoLarsCV                                  0.15       0.17  0.92        0.19\n",
              "KernelRidge                                  0.15       0.17  0.92       12.21\n",
              "RidgeCV                                      0.15       0.17  0.92        0.10\n",
              "Ridge                                        0.15       0.17  0.92        0.06\n",
              "TransformedTargetRegressor                   0.15       0.17  0.92        0.04\n",
              "LinearRegression                             0.15       0.17  0.92        0.04\n",
              "SGDRegressor                                 0.15       0.17  0.92        0.10\n",
              "NuSVR                                        0.15       0.16  0.92       12.01\n",
              "LarsCV                                       0.14       0.16  0.92        0.18\n",
              "SVR                                          0.14       0.16  0.93       11.32\n",
              "Lars                                         0.13       0.15  0.93        0.05\n",
              "OrthogonalMatchingPursuitCV                  0.11       0.13  0.94        0.08\n",
              "OrthogonalMatchingPursuit                    0.11       0.13  0.94        0.03\n",
              "TweedieRegressor                             0.11       0.12  0.95        0.04\n",
              "GeneralizedLinearRegressor                   0.11       0.12  0.95        0.05\n",
              "KNeighborsRegressor                          0.08       0.10  0.96        2.13\n",
              "MLPRegressor                                 0.04       0.06  0.98       10.39\n",
              "HuberRegressor                               0.04       0.05  0.98        0.46\n",
              "GaussianProcessRegressor                     0.02       0.03  0.99       29.17\n",
              "LinearSVR                                    0.01       0.03  0.99        1.40\n",
              "LassoLars                                   -0.02      -0.00  1.01        0.06\n",
              "Lasso                                       -0.02      -0.00  1.01        0.04\n",
              "ElasticNet                                  -0.02      -0.00  1.01        0.03\n",
              "DummyRegressor                              -0.02      -0.00  1.01        0.03\n",
              "RANSACRegressor                             -0.20      -0.18  1.09        0.27\n",
              "DecisionTreeRegressor                       -0.48      -0.45  1.22        0.25\n",
              "PassiveAggressiveRegressor                  -0.87      -0.84  1.37        0.05\n",
              "ExtraTreeRegressor                          -0.98      -0.94  1.41        0.13\n",
              "AdaBoostRegressor                           -1.70      -1.65  1.64        1.19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQBjAlRsHhU4"
      },
      "source": [
        "# Modeling - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpxaylKk-6CQ"
      },
      "source": [
        "* Quick recap in our raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfKHc63v-6Zm"
      },
      "source": [
        "print(df.shape)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD6B3CuhiDMT"
      },
      "source": [
        "* Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFzP2iGiIk1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['RainfallTomorrow'],axis=1),\n",
        "                                    df['RainfallTomorrow'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt60YblgiF0y"
      },
      "source": [
        "* Use lazy-predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLkUcA7riJD0"
      },
      "source": [
        "* Create Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imwlDdi6iJK-"
      },
      "source": [
        "pipeline_regressor = PipelineRegressor()\n",
        "pipeline_regressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfRpKC4Ykreg"
      },
      "source": [
        "* Fit Cluster pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAiyUpTWHjQh"
      },
      "source": [
        "X = df.copy()\n",
        "\n",
        "pipeline_cluster = PipelineCluster()\n",
        "pipeline_cluster.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AU1E4IdkyLd"
      },
      "source": [
        "* Cluster model output is an array with clusters labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lx5EqalOtv"
      },
      "source": [
        "pipeline_cluster['model'].labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRk0uyz1lSIW"
      },
      "source": [
        "pipeline_cluster['model'].labels_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnJzUxAmkv07"
      },
      "source": [
        "* The goal is to merge cluster labels to our data.\n",
        "  * However, the pipeline dropped rows from ['RainfallToday', 'RainToday'] and had AddMissingIndicatorFlag in the process\n",
        "  * Before merging, we need to adjust it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAUY6-_6A-rN"
      },
      "source": [
        "drop_imputer = DropMissingData(variables =['RainfallToday' , 'RainToday'])  #,'RainfallTomorrow','RainTomorrow'])\n",
        "X = drop_imputer.fit_transform(X)\n",
        "\n",
        "na_imputer =  AddMissingIndicator(variables= ['Sunshine', 'Evaporation', 'Cloud3pm',\n",
        "                                           'Cloud9am', 'Pressure9am', 'Pressure3pm',\n",
        "                                            'WindDir9am', 'WindGustDir', 'WindGustSpeed',\n",
        "                                            'Humidity3pm', 'WindDir3pm', 'Temp3pm',\n",
        "                                            #  'RainfallTomorrow','RainTomorrow',  ##########\n",
        "                                            'RainfallToday', 'RainToday',\n",
        "                                            'WindSpeed3pm', 'Humidity9am','Temp9am',\n",
        "                                            'WindSpeed9am', 'MinTemp','MaxTemp'])\n",
        "X = na_imputer.fit_transform(X)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKT5IjmTmei8"
      },
      "source": [
        "* We add a column \"Cluster\" to the data and check clusters distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow8B0xVdmlgK"
      },
      "source": [
        "X['Clusters'] = pipeline_cluster['model'].labels_\n",
        "X['Clusters'] = X['Clusters'].astype('object')\n",
        "\n",
        "print(f\"* Clusters frequencies \\n{ X['Clusters'].value_counts(normalize=True)} \\n\\n\")\n",
        "X['Clusters'].value_counts().sort_values().plot(kind='bar');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OhXSh7536Ye"
      },
      "source": [
        "* Clusters don't look to be imbalanced\n",
        "* This is how our data look like from now\n",
        "  * Check the last column: Clusters\n",
        "  * Quick reminder: The data is unprocessed (data cleaning, feat eng); except for the part DropMissingData(variables =['RainfallToday', 'RainToday'])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAVrYJEqxYyG"
      },
      "source": [
        "print(X.shape)\n",
        "X.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtmFP_Ulpnd"
      },
      "source": [
        "# Regressor Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAJj6IZqmrxx"
      },
      "source": [
        "* To evaluate clusters silhouete we need:\n",
        "  * data transformed (transform data in the pipeline wihout model step)\n",
        "  * clusters arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJPFLoTciOI5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTWTf1rgkQ7b"
      },
      "source": [
        "# Classifier to explain cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipsJSzhhkUiu"
      },
      "source": [
        "* We need to find the most relevant variables, to define each cluster in terms of each relevant variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeLq81sm2yAg"
      },
      "source": [
        "df_clf = X.copy() #.sample(frac=0.051, random_state=config.RANDOM_STATE)\n",
        "df_clf['Clusters'] = df_clf['Clusters'].astype('int32')\n",
        "print(df_clf.shape)\n",
        "df_clf.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b3Ei6Os5X3s"
      },
      "source": [
        "* Split Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgHXehCVyzUl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df_clf.drop(['Clusters'],axis=1),\n",
        "                                    df_clf['Clusters'],\n",
        "                                    test_size=config.TEST_SIZE,\n",
        "                                    random_state=config.RANDOM_STATE,\n",
        "                                    stratify=df_clf['Clusters']\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EZUk-uV5aN8"
      },
      "source": [
        "* Create pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R7xdg1Av0Ce"
      },
      "source": [
        "pipeline_clf_cluster = PipelineClf2ExplainClusters()\n",
        "pipeline_clf_cluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9nz9-UeBl0P"
      },
      "source": [
        "pipeline_clf_cluster['MedianImputer'].imputer_dict_ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Cjsn6l5cqF"
      },
      "source": [
        "* Fit pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0QPwTqa0OcY"
      },
      "source": [
        "pipeline_clf_cluster.fit(X_train,y_train)\n",
        "\n",
        "# do GridCV after"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z05LMFoZ4T2K"
      },
      "source": [
        " * Evaluate model performance on Train and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1iqL2Kc544K"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\n",
        "      classification_report(y_train, pipeline_clf_cluster.predict(X_train))\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oo4xJMZ615p"
      },
      "source": [
        "print(\n",
        "      classification_report(y_test, pipeline_clf_cluster.predict(X_test))\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEwjHBSh5ejG"
      },
      "source": [
        "* Check main features importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N7Mc3mrAYLq"
      },
      "source": [
        "df_feature_importance = pd.DataFrame(data={\n",
        "    'Attribute': df_clf.columns[pipeline_clf_cluster['feat_selection'].get_support()],\n",
        "    'Importance': pipeline_clf_cluster['model'].feature_importances_\n",
        "  })\n",
        "\n",
        "df_feature_importance.sort_values(by='Importance', ascending=False).plot(kind='bar',x='Attribute',y='Importance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQblpQISv0Fd"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "_parameters = {\n",
        "    'model__n_estimators':[50], # [100,200,50],\n",
        "    'model__max_depth': [3] # [None,3,10]\n",
        "}\n",
        "\n",
        "\n",
        "_pipe = GridSearchCV(\n",
        "\t\testimator = pipeline_clf_cluster,\n",
        "\t\tparam_grid = _parameters, \n",
        "\t\tcv=2,n_jobs=-2,verbose=2)\n",
        "_pipe.fit(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4baRUyFv0IL"
      },
      "source": [
        "PipelineToDeploy = _pipe.best_estimator_\n",
        "PipelineToDeploy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckZ0bHjDyrMr"
      },
      "source": [
        "_pipe.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJwzpgGwys-x"
      },
      "source": [
        "X_train.columns[PipelineToDeploy['feat_selection'].get_support()].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMUEqXK0yu1F"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print( classification_report(y_test, PipelineToDeploy.predict(X_test)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUo1Odq3kRD3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2ywCxJmkRQn"
      },
      "source": [
        "# Clusters Profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73J7J65v4O_d"
      },
      "source": [
        "* Main variables that define a cluster\n",
        "\n",
        "1.   Using main features from previous classifier\n",
        "2.   And variables we are interested (busines acumen)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-k5S-NKFTMW"
      },
      "source": [
        "main_clusters_variables =  df_feature_importance['Attribute'].to_list() + ['State','RainToday','Cloud3pm']\n",
        "main_clusters_variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PztdhjGl4Vkg"
      },
      "source": [
        "df_cluster_profile = X.copy()\n",
        "for col in ['Cloud9am','Cloud3pm']:\n",
        "  df_cluster_profile[col] =df_cluster_profile[col].astype('object')\n",
        "\n",
        "\n",
        "df_cluster_profile = df_cluster_profile.filter(items=main_clusters_variables+['Clusters'],axis=1)\n",
        "\n",
        "num_var = df_cluster_profile.filter(main_clusters_variables,axis=1).select_dtypes(include=['number']).columns.to_list()\n",
        "categorical_var = df_cluster_profile.filter(main_clusters_variables,axis=1).select_dtypes(exclude=['number']).columns.to_list()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nl2EOOwtHdc"
      },
      "source": [
        "df_cluster_profile.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NBCTceJbgRu"
      },
      "source": [
        "## Custom Functions for Cluster Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35a9x3gPbnwu"
      },
      "source": [
        "* Distribution profile for all clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqEazT5blBg"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "def PlotClustersDistribution(df,num_var,categorical_var):\n",
        "  for col in num_var:\n",
        "    print(f\"* {col} distribution per cluster\")\n",
        "    plt.figure(figsize=(10,5));\n",
        "    sns.kdeplot(data=df, x=col, hue=\"Clusters\",palette='Set2')\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "  for col in categorical_var:\n",
        "    print(f\"* {col} distribution per cluster\")\n",
        "    plt.figure(figsize=(15,5));\n",
        "    sns.countplot(data=df.sort_values(by=col), hue=col, x=\"Clusters\",palette='Set2')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEGYqOOJcKPK"
      },
      "source": [
        "* Individual Cluster Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oxlK-aOcKX3"
      },
      "source": [
        "# def IndividualClusterAnalysis(df_cluster_profile):\n",
        "\n",
        "#   sns.set_style(\"darkgrid\")\n",
        "#   for cluster in df_cluster_profile.sort_values(by='Clusters')['Clusters'].unique():\n",
        "\n",
        "#     df_cluster = df_cluster_profile.query(f\"Clusters == {cluster}\")\n",
        "#     print(f\"=================== Cluster {cluster} ===================\")\n",
        "    \n",
        "#     for col in num_var:\n",
        "#       print(f\"* {col} distribution for cluster {cluster}\")\n",
        "#       plt.figure(figsize=(10,5));\n",
        "#       sns.histplot(data=df_cluster, x=col)\n",
        "#       plt.show();\n",
        "\n",
        "#       iqr = df_cluster[col].quantile([0.25,0.75])\n",
        "#       print(f\"* IQR: {iqr[0.25]} - {iqr[0.75]}\")\n",
        "#       print(\"\\n\")\n",
        "\n",
        "#     for col in categorical_var:\n",
        "#       print(f\"* {col} distribution for cluster {cluster}\")\n",
        "#       try:\n",
        "#         plt.figure(figsize=(10,5));\n",
        "#         sns.countplot(data=df_cluster, x=col)\n",
        "#         freq = df_cluster[col].value_counts()\n",
        "#         plt.show()\n",
        "#       except Exception as e:\n",
        "#         print(e)\n",
        "#       print(\"\\n\")\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZMr-wiudEkb"
      },
      "source": [
        "* Description All Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lpRVDqTdEul"
      },
      "source": [
        "def Clusters_IndividualDescription(EDA_Cluster,cluster):\n",
        "\n",
        "  ClustersDescription = pd.DataFrame(columns=EDA_Cluster.columns)\n",
        "  for col in EDA_Cluster.columns:\n",
        "    \n",
        "    try:  # eventually a given cluster will have only mssing data for a given variable\n",
        "      \n",
        "      if EDA_Cluster[col].dtypes == 'object':\n",
        "        \n",
        "        top_frequencies = EDA_Cluster.dropna(subset=[col])[[col]].value_counts(normalize=True).nlargest(n=3)\n",
        "        Description = ''\n",
        "        \n",
        "        for x in range(len(top_frequencies)):\n",
        "          freq = top_frequencies.iloc[x]\n",
        "          category = top_frequencies.index[x][0]\n",
        "          CategoryPercentage = int(round(freq*100,0))\n",
        "          statement =  f\"'{category}' ({CategoryPercentage}%) ; \"  \n",
        "          Description = Description + statement\n",
        "        \n",
        "        ClustersDescription.at[0,col] = Description[:-2]\n",
        "\n",
        "\n",
        "      \n",
        "      elif EDA_Cluster[col].dtypes in ['float', 'int']:\n",
        "        DescStats = EDA_Cluster.dropna(subset=[col])[[col]].describe()\n",
        "        Q1 = int(round(DescStats.iloc[4,0],0))\n",
        "        Q3 = int(round(DescStats.iloc[6,0],0))\n",
        "        Description = f\"{Q1} -- {Q3}\"\n",
        "        ClustersDescription.at[0,col] = Description\n",
        "    \n",
        "    \n",
        "    except Exception as e:\n",
        "      ClustersDescription.at[0,col] = 'Not available'\n",
        "      print(f\"** Error Exception: {e} - cluster {cluster}, variable {col}\")\n",
        "  \n",
        "  ClustersDescription['Cluster'] = str(cluster)\n",
        "  \n",
        "  return ClustersDescription\n",
        "\n",
        "\n",
        "def DescriptionAllClusters(df_cluster_profile):\n",
        "\n",
        "  DescriptionAllClusters = pd.DataFrame(columns=df_cluster_profile.drop(['Clusters'],axis=1).columns)\n",
        "  for cluster in df_cluster_profile.sort_values(by='Clusters')['Clusters'].unique():\n",
        "    \n",
        "      EDA_ClusterSubset = df_cluster_profile.query(f\"Clusters == {cluster}\").drop(['Clusters'],axis=1)\n",
        "      ClusterDescription = Clusters_IndividualDescription(EDA_ClusterSubset,cluster)\n",
        "      DescriptionAllClusters = DescriptionAllClusters.append(ClusterDescription)\n",
        "\n",
        "  \n",
        "  DescriptionAllClusters.set_index(['Cluster'],inplace=True)\n",
        "  return DescriptionAllClusters\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeOOWOX14vQw"
      },
      "source": [
        "## All Cluster Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDhycaSEdORm"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "DescriptionAllClusters(df_cluster_profile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxpVsX_t9Pwz"
      },
      "source": [
        "PlotClustersDistribution(df=df_cluster_profile,num_var=num_var,categorical_var=categorical_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdkP_KIA4ylt"
      },
      "source": [
        "## Individual Cluster Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWpacqZncG29"
      },
      "source": [
        "# IndividualClusterAnalysis(df_cluster_profile)  # maybe remove? analysis above is better"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}