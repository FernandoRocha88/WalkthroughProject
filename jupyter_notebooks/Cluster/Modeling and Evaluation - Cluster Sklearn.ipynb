{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Modeling and Evaluation - Cluster Sklearn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Fit and evaluate a cluster model to group australian cities/states based on weather information\n",
        "* Understand profile for each cluster\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* content/WalkthroughProject/outputs/datasets/collection/WeatherAustralia.csv\n",
        "* instructions on which variables to use for data cleaning and feature engineering. They are found on its respectives notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Cluster model\n",
        "* Classifier modeel to explain clusters\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "\n",
        "* how to translate cluster to map?\n",
        "  * dataset is time series, each row is a day for each city\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbuGQj9lDAEo"
      },
      "source": [
        "# Install and Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAx1yVscyB3M"
      },
      "source": [
        "* You eventually will need to restart runtime when installing packages, please note cell output when installing a package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBfLDnhx-2k"
      },
      "source": [
        "! pip install feature-engine==1.0.2\n",
        "! pip install scikit-learn==0.23.2\n",
        "! pip install yellowbrick==1.2\n",
        "\n",
        "\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUFuYskeybZL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit â†’ Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd",
        "outputId": "00dbcae3-59f2-437b-ce09-5d60f07c201e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHiVgPviuMx"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtPQ7EnPiuMy"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDHrzxEiuMz"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8aYwLkiuMz",
        "outputId": "00528d8d-d1a3-4678-9638-10abce273a1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* Thanks for inserting your credentials!\n",
            "* You may now Clone your Repo to this Session, then Connect this Session to your Repo.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JjRkDt1eOAr"
      },
      "source": [
        "* **Credentials format disclaimer**: when opening Jupyter notebooks in Colab that are hosted at GitHub, we ask you to not consider special characters in your **password**, like @ ! \" # $ % & ' ( ) * + , - . / :;< = > ? @ [\\ ]^_ ` { } | ~\n",
        "  * Otherwise it will not work properly the git push command, since the credentials are concatenated in the command: username:password@github.com/username/repo , the git push command will not work properly when these terms have special characters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_amd2ygiuM0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I2eQe-YiuM0"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfD0o1u1iuM0"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGOPTqcmiuM1",
        "outputId": "bc9ec718-59ab-4d0f-d33a-712d03cc3683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'WalkthroughProject'...\n",
            "remote: Enumerating objects: 934, done.\u001b[K\n",
            "remote: Counting objects: 100% (490/490), done.\u001b[K\n",
            "remote: Compressing objects: 100% (423/423), done.\u001b[K\n",
            "remote: Total 934 (delta 297), reused 115 (delta 46), pack-reused 444\u001b[K\n",
            "Receiving objects: 100% (934/934), 31.68 MiB | 7.95 MiB/s, done.\n",
            "Resolving deltas: 100% (523/523), done.\n",
            "\n",
            "\n",
            "/content/WalkthroughProject\n",
            "\n",
            "\n",
            "* Current session directory is:/content/WalkthroughProject\n",
            "* You may refresh the session folder to access WalkthroughProject folder.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uhzcFjeiuM1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS3yEKFJiuM1"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_tFmsYgiuM2"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CveMisgfiuM2"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the sessions, update the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "# import uuid\n",
        "# file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "# with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "# print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "# ! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "# print(\"\\n\\n\")\n",
        "# os.remove(f\"{file_name}.txt\")\n",
        "# ! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpFreVRiuM3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "257gMsNhiuM3"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUla5863TKyk"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzjZgWV-TMOB"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_xeleqiuM4"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpFefbLXiuM4"
      },
      "source": [
        "CommitMsg = \"update\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msFKrJ6fiuM5"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxYGf_yiuM5"
      },
      "source": [
        "!git push origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXKlJFX0iuM5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7CNgZ_TiuM6"
      },
      "source": [
        "### **Delete** Cloned Repo from current Session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cobdGQGZfZG7"
      },
      "source": [
        "* Delete cloned repo and move current directory to /content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UACixuaiuM6",
        "outputId": "0089e933-ad03-4dfc-e58c-c0ef11e75d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content\n",
        "!rm -rf {os.environ['RepoName']}\n",
        "\n",
        "print(f\"\\n * Please refresh session folder to validate that {os.environ['RepoName']} folder was removed from this session.\")\n",
        "print(f\"\\n\\n* Current session directory is:  {os.getcwd()}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "\n",
            " * Please refresh session folder to validate that WalkthroughProject folder was removed from this session.\n",
            "\n",
            "\n",
            "* Current session directory is:  /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MKNQXhQiuM7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7DU_ekbtX8",
        "outputId": "fdae0eb9-df0e-4bde-bc20-79d62e8a00b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/WalkthroughProject/outputs/datasets/collection/WeatherAustralia.csv\")\n",
        "df.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 27 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Date              145460 non-null  object \n",
            " 1   Location          145460 non-null  object \n",
            " 2   MinTemp           143975 non-null  float64\n",
            " 3   MaxTemp           144199 non-null  float64\n",
            " 4   RainfallToday     142199 non-null  float64\n",
            " 5   Evaporation       82670 non-null   float64\n",
            " 6   Sunshine          75625 non-null   float64\n",
            " 7   WindGustDir       135134 non-null  object \n",
            " 8   WindGustSpeed     135197 non-null  float64\n",
            " 9   WindDir9am        134894 non-null  object \n",
            " 10  WindDir3pm        141232 non-null  object \n",
            " 11  WindSpeed9am      143693 non-null  float64\n",
            " 12  WindSpeed3pm      142398 non-null  float64\n",
            " 13  Humidity9am       142806 non-null  float64\n",
            " 14  Humidity3pm       140953 non-null  float64\n",
            " 15  Pressure9am       130395 non-null  float64\n",
            " 16  Pressure3pm       130432 non-null  float64\n",
            " 17  Cloud9am          89572 non-null   float64\n",
            " 18  Cloud3pm          86102 non-null   float64\n",
            " 19  Temp9am           143693 non-null  float64\n",
            " 20  Temp3pm           141851 non-null  float64\n",
            " 21  RainToday         142199 non-null  object \n",
            " 22  RainTomorrow      142193 non-null  object \n",
            " 23  RainfallTomorrow  142017 non-null  float64\n",
            " 24  Latitude          145460 non-null  float64\n",
            " 25  Longitude         145460 non-null  float64\n",
            " 26  State             145460 non-null  object \n",
            "dtypes: float64(19), object(8)\n",
            "memory usage: 30.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3u49Wn7byHA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krjAk78Tbyhv"
      },
      "source": [
        "# Cluster Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kD7PZ5kZkBT"
      },
      "source": [
        "## Custom transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A96j6zLKZz7N"
      },
      "source": [
        "  * convert ['Cloud9am','Cloud3pm'] to categorical\n",
        "  * get Get Day, Month, Year, Weekday, IsWeekend from Date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_tTrXFaWSIU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Convert ['Cloud9am','Cloud3pm'] to categorical\n",
        "class ConvertToCategorical(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variables=None):\n",
        "      if not isinstance(variables, list):\n",
        "          self.variables = [variables]\n",
        "      else:\n",
        "          self.variables = variables\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      X = X.copy()\n",
        "      for feature in self.variables:\n",
        "          X[feature] = X[feature].astype('object')\n",
        "\n",
        "      return X\n",
        "\n",
        "\n",
        "# Get Day, Month, Year, Weekday, IsWeekend from Date\n",
        "class GetFeaturesFromDate(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, variable=None):\n",
        "      self.variable = variable\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      X = X.copy()\n",
        "      X[self.variable] = pd.to_datetime(X[self.variable])\n",
        "      X['Day'] = X[self.variable].dt.day\n",
        "      X['Month'] = X[self.variable].dt.month\n",
        "      X['Year'] = X[self.variable].dt.year\n",
        "      X['WeekDay']= X[self.variable].dt.weekday\n",
        "      X['IsWeekend'] = X['WeekDay'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "\n",
        "      return X\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZWZHhpYaDjf"
      },
      "source": [
        "## Cluster Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL52aj1NmyX8"
      },
      "source": [
        "* add PCA in the pipeline, consider kmeans, fit with gridcv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xW_ndF7ZS1-"
      },
      "source": [
        "convert_cat = ConvertToCategorical(variables=['Cloud9am','Cloud3pm'])\n",
        "convert_date = GetFeaturesFromDate(variable='Date')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnS7v_HVb1db"
      },
      "source": [
        "from config import config\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import DropMissingData\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.transformation import (LogTransformer,\n",
        "                                           ReciprocalTransformer,\n",
        "                                           PowerTransformer,\n",
        "                                           BoxCoxTransformer,\n",
        "                                           YeoJohnsonTransformer)\n",
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "from feature_engine.encoding import RareLabelEncoder\n",
        "from feature_engine.encoding import CountFrequencyEncoder\n",
        "\n",
        "### PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.cluster import KMeans\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6keis6ao8LA"
      },
      "source": [
        "ml_pipeline_cluster = Pipeline(\n",
        "    [\n",
        "     ### Data Cleaning\n",
        "     (\"ConvertToCategorical\",ConvertToCategorical(variables = ['Cloud9am','Cloud3pm'])\n",
        "     ),\n",
        "\n",
        "     (\"GetFeaturesFromDate\",GetFeaturesFromDate(variable= 'Date')\n",
        "     ),\n",
        "\n",
        "     (\"DropFeatures\",DropFeatures(features_to_drop = ['Sunshine','Evaporation','Cloud9am','Date'])\n",
        "     ),\n",
        "\n",
        "     (\"DropMissingData\",DropMissingData(variables =['RainTomorrow', 'RainfallToday', 'RainToday','RainfallTomorrow'])\n",
        "     ),\n",
        "\n",
        "     (\"CategoricalImputer\",CategoricalImputer(variables=['WindDir9am', 'WindGustDir', 'WindDir3pm','Cloud3pm'],\n",
        "                                              imputation_method='missing',fill_value='Missing')\n",
        "     ),\n",
        "\n",
        "     (\"MedianImputer\",MeanMedianImputer(imputation_method='median',\n",
        "                                        variables=['Pressure3pm', 'Pressure9am','WindGustSpeed',\n",
        "                                                   'Humidity3pm', 'Temp3pm', 'WindSpeed3pm', 'Humidity9am',\n",
        "                                                   'WindSpeed9am','Temp9am','MaxTemp']\n",
        "                                        )\n",
        "     ),\n",
        "\n",
        "     (\"MeanImputer\",MeanMedianImputer(imputation_method='mean',variables=['MinTemp'])\n",
        "     ),\n",
        "\n",
        "     ### Feature Engineering\n",
        "\n",
        "     (\"Winsorizer_iqr\",Winsorizer(capping_method='iqr',tail='both', fold=3,variables = ['RainfallToday'])\n",
        "     ),\n",
        "\n",
        "\n",
        "     (\"PowerTransformer\",PowerTransformer(variables = ['WindSpeed3pm','Humidity3pm'])\n",
        "     ),\n",
        "\n",
        "     (\"YeoJohnsonTransformer\",YeoJohnsonTransformer(variables=['RainfallToday','WindGustSpeed','WindSpeed9am','Humidity9am'])\n",
        "     ),\n",
        "\n",
        "     (\"EqualFrequencyDiscretiser\",EqualFrequencyDiscretiser(q=5,variables = ['Latitude','Longitude' ])\n",
        "     ),\n",
        "\n",
        "     (\"RareLabelEncoder_tol5\",RareLabelEncoder(tol=0.05, n_categories=2, variables=['WindDir3pm'])\n",
        "     ),\n",
        "\n",
        "     (\"RareLabelEncoder_tol7\",RareLabelEncoder(tol=0.06, n_categories=2, variables=['State'])\n",
        "     ),\n",
        "\n",
        "     (\"CountEncoder\",CountFrequencyEncoder(encoding_method='count',\n",
        "                                           variables = ['Location','WindGustDir','WindDir9am','WindDir3pm','State'])\n",
        "     ),\n",
        "\n",
        "     ### Feature Selection - Dimensionality Reduction    \n",
        "     (\"PCA\",PCA(n_components=3,random_state=config.RANDOM_STATE)\n",
        "     ),\n",
        "\n",
        "     ### Feature Scaling\n",
        "     (\"scaler\",StandardScaler()\n",
        "     ),\n",
        "     \n",
        "     ### Model\n",
        "     (\"model\",KMeans(n_clusters=6,random_state=config.RANDOM_STATE)\n",
        "     )\n",
        "\n",
        "    ])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJcdBCF3o8PZ",
        "outputId": "009bd5f8-cab7-410a-c5ee-0c8d590db00d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ml_pipeline_cluster"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ConvertToCategorical',\n",
              "                 ConvertToCategorical(variables=['Cloud9am', 'Cloud3pm'])),\n",
              "                ('GetFeaturesFromDate', GetFeaturesFromDate(variable='Date')),\n",
              "                ('DropFeatures',\n",
              "                 DropFeatures(features_to_drop=['Sunshine', 'Evaporation',\n",
              "                                                'Cloud9am', 'Date'])),\n",
              "                ('DropMissingData',\n",
              "                 DropMissingData(variables=['RainTomorrow', 'RainfallToday',\n",
              "                                            'RainToday', 'RainfallT...\n",
              "                 RareLabelEncoder(n_categories=2, variables=['WindDir3pm'])),\n",
              "                ('RareLabelEncoder_tol7',\n",
              "                 RareLabelEncoder(n_categories=2, tol=0.06,\n",
              "                                  variables=['State'])),\n",
              "                ('CountEncoder',\n",
              "                 CountFrequencyEncoder(variables=['Location', 'WindGustDir',\n",
              "                                                  'WindDir9am', 'WindDir3pm',\n",
              "                                                  'State'])),\n",
              "                ('PCA', PCA(n_components=3, random_state=0)),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('model', KMeans(n_clusters=6, random_state=0))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TFc_WN_G_La"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw9NtDj4EtEJ"
      },
      "source": [
        "# Elbow Analysis and Quick Silhouete Visualizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOXb_H6iGx6U"
      },
      "source": [
        "* Prepare data for analysis\n",
        "  * You need to clean and feature engineer your data using the pipeline (but the model step)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVaMnb9vGyBw"
      },
      "source": [
        "from scr.FeatEngineering.ApplyPipeline_FeatEng import ApplyFeatEngPipeline\n",
        "\tdf = ApplyFeatEngPipeline(df)\n",
        " df = df.drop([config.TARGET],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_1KLQujEvgi"
      },
      "source": [
        "* Elbow Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZBcHjt7EwFT"
      },
      "source": [
        "nClusters = 4 # amount of  clusters used for silhoute visualizer\n",
        "# i have to break in 2 moments, first elboow to know nb ofcluster, then silhoute visualizer with that nb of clusters\n",
        "KMeansAlgoAnalysis(df,nClusters)\n",
        "\n",
        "\n",
        "\n",
        "# it needs the data already transformed by the cluster pipeline\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "visualizer = KElbowVisualizer(KMeans(), k=(1,16))\n",
        "visualizer.fit(df) \n",
        "visualizer.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMPygnLNHDnV"
      },
      "source": [
        "* Quick Silhouete Visualizer# i"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MjrBCqAGcbD"
      },
      "source": [
        "# it needs the data already transformed by the cluster pipeline\n",
        "\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\tfrom sklearn.cluster import KMeans\n",
        "\tvisualizer = SilhouetteVisualizer(\n",
        "\t\tKMeans(n_clusters=n_clusters),\n",
        "\t\tcolors='yellowbrick')\n",
        "\tvisualizer.fit(df)\n",
        "\tvisualizer.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGXCMGSjD7J6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrr31sD9DyvY"
      },
      "source": [
        "# Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1fnArcWET0D"
      },
      "source": [
        "* Calculate each component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoKXAhmqD5H3"
      },
      "source": [
        "from scr.FeatEngineering.ApplyPipeline_FeatEng import ApplyFeatEngPipeline\n",
        "\tdf_orginal = ApplyFeatEngPipeline(df_orginal)\n",
        "\n",
        "\tfrom sklearn.decomposition import PCA\n",
        "\n",
        "\t# if there is a intended target, remove\n",
        "\ttry: dfNoTarget = df_orginal.drop([config.TARGET],axis=1)\n",
        "\texcept: dfNoTarget = df_orginal.copy()\n",
        "\n",
        "\tpca = PCA(n_components=n_components).fit(dfNoTarget)\n",
        "\tx_PCA = pca.transform(dfNoTarget) # array with transformed PCA\n",
        "\n",
        "\t# generate datframe according to n_components\n",
        "\tComponentsList = [\"Component \" + str(number) for number in range(n_components)]\n",
        "\tdfPCA = pd.DataFrame(data=x_PCA, columns=ComponentsList)\n",
        "\n",
        "\ttry:\n",
        "\t\tdfPCA_WithTarget = dfPCA.copy()\n",
        "\t\tdfPCA_WithTarget[config.TARGET] = df_orginal[config.TARGET].astype(str)\n",
        "\texcept:\n",
        "\t\tpass # dataset doenst have TARGET\n",
        "\n",
        "\n",
        "\t# how each component explains data variance\n",
        "\tdfExplVarRatio = pd.DataFrame(\n",
        "\t\tdata=pca.explained_variance_ratio_,\n",
        "\t\tindex=ComponentsList,\n",
        "\t\tcolumns=['Explained Variance Ratio'])\n",
        "\tPercentageOfDataExplained = round(float(dfExplVarRatio['Explained Variance Ratio'].sum()),4) * 100\n",
        "\n",
        "fig = px.scatter_3d(dfPCA, x='Component 0', y='Component 1', z='Component 2')\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=0)))\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sF6DBzMEWNk"
      },
      "source": [
        "* PCA summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ps2ThgsEPMO"
      },
      "source": [
        "st.write(\n",
        "\t# \"* PCA - Transformed dataset:\",dfPCA.shape,dfPCA,\n",
        "\t\"* Explained Variance Ratio per PCA Component: \",dfExplVarRatio)\n",
        "\tst.write(f\"> * Together, the components explain {PercentageOfDataExplained} % of the data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAMADLcmEa4d"
      },
      "source": [
        "* Present explained variance per component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynQDkj3BERao"
      },
      "source": [
        "df_comp = pd.DataFrame(pca.components_, columns=dfNoTarget.columns)\n",
        "\tfig = px.imshow(df_comp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P12u4jyKERs_"
      },
      "source": [
        "st.write(\"* Heatmap: Feature Composition for each PCA Component\")\n",
        "st.plotly_chart(fig, use_container_width=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQBjAlRsHhU4"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAiyUpTWHjQh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXtmFP_Ulpnd"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAJj6IZqmrxx"
      },
      "source": [
        "* use silhouete score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzqxawC8lq1R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "\n",
        "def Cluster_Silhouette(X,Clusters):\n",
        "\n",
        "\tcluster_labels  = Clusters\n",
        "\tn_clusters = len(set(cluster_labels))\n",
        "\n",
        "\tprint(\" Silhouette plot for each cluster\")\n",
        "\tfig, (ax1) = plt.subplots(1, 1)\n",
        "\tfig.set_size_inches(18, 7)\n",
        "\tax1.set_xlim([-0.1, 1])\n",
        "\tax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\t\n",
        "\tsilhouette_avg = silhouette_score(X, cluster_labels,random_state=config.RANDOM_STATE)\n",
        "\tprint(\"* The silhouette average score is \",str(round(float(silhouette_avg),2)))\n",
        "\t# print(\n",
        "\t# \tf\"* Silhouette assesses consistency within clusters - \"\n",
        "\t# \tf\"[Link 1] (https://en.wikipedia.org/wiki/Silhouette_(clustering)) and \"\n",
        "\t# \tf\"[Link 2] (https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam) \")\n",
        "\n",
        "\n",
        "\tsample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\ty_lower = 10\n",
        "\tfor i in range(n_clusters):\n",
        "\t\tith_cluster_silhouette_values = \\\n",
        "\t\t\tsample_silhouette_values[cluster_labels == i]\n",
        "\t\tith_cluster_silhouette_values.sort()\n",
        "\t\tsize_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "\t\ty_upper = y_lower + size_cluster_i\n",
        "\t\tcolor = cm.nipy_spectral(float(i) / n_clusters)\n",
        "\t\tax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "\t\t\t\t\t\t\t0, ith_cluster_silhouette_values,\n",
        "\t\t\t\t\t\t\tfacecolor=color, edgecolor=color, alpha=0.7)\n",
        "\t\tax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\t\ty_lower = y_upper + 10\n",
        "\n",
        "\tax1.set_title(\"The silhouette plot for each cluster\")\n",
        "\tax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "\tax1.set_ylabel(\"Cluster label\")\n",
        "\tax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\tax1.set_yticks([])\n",
        "\tax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NkmTmxMlsIB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CeuXU4onYHh"
      },
      "source": [
        "* plot clusters in 3d scatter plot, using PCA for dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7MqATPNlsKk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgRHmWlHlsR6"
      },
      "source": [
        "# Plot Clusters in a map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ducvyfimPvx"
      },
      "source": [
        "* I need a dataframe with unique locations, their lat/long/state/cluster\n",
        "* drop duplicates for location??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FHBdHBelvIW"
      },
      "source": [
        "# https://towardsdatascience.com/interactive-maps-with-python-pandas-and-plotly-following-bloggers-through-sydney-c24d6f30867e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6H-3KlmGOC"
      },
      "source": [
        "import plotly.express as px \n",
        "\n",
        "\n",
        "fig = px.scatter_mapbox(xxxxx,\n",
        "                        lat=\"Latitude\", lon=\"Longitude\", color=\"Cluster\",\n",
        "                        hover_data=['State','Location'],\n",
        "                        # size='RainfallToday',\n",
        "                        zoom=2.5,\n",
        "                        mapbox_style=\"open-street-map\",\n",
        "                        # animation_frame='Month',\n",
        "                        center={\"lat\":-27,\"lon\":133},\n",
        "                        size_max=15\n",
        "                        )\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}